apiVersion: ray.io/v1
kind: RayJob
metadata:
  name: llm
  namespace: ray
spec:
  entrypoint: python /home/ray/scripts/entity_recognition.py --skip-training
  runtimeEnvYAML: |
    pip:
      - xgrammar==0.1.11
      - pynvml==12.0.0
      - hf_transfer==0.1.9
      - tensorboard==2.19.0
      - "llamafactory@git+https://github.com/hiyouga/LLaMA-Factory.git@v0.9.3#egg=llamafactory"
      - IPython
    env_vars:
      HF_HUB_ENABLE_HF_TRANSFER: "1"
      RAY_ACCEL_ENV_VAR_OVERRIDE_ON_ZERO: "0"
      RAY_OVERRIDE_JOB_RUNTIME_ENV: "1"

  shutdownAfterJobFinishes: false   # keep cluster alive to inspect results
  # ttlSecondsAfterFinished: 3600     # clean up 1 h after completion

  rayClusterSpec:
    rayVersion: "2.53.0"
    enableInTreeAutoscaling: false

    headGroupSpec:
      rayStartParams:
        num-cpus: "0" # don't schedule training workers on head
        dashboard-host: "0.0.0.0"
        disable-usage-stats: "true"
      template:
        spec:
          nodeSelector:
            agentpool: system
          containers:
            - name: ray-head
              image: rayproject/ray:2.53.0
              env:
                - name: RAY_DISABLE_DOCKER_CPU_WARNING
                  value: "1"
                - name: RAY_SCHEDULER_EVENTS
                  value: "0"
              ports:
                - containerPort: 6379
                  name: gcs-server
                - containerPort: 8265
                  name: dashboard
                - containerPort: 10001
                  name: client
              resources:
                limits:
                  cpu: "8"
                  memory: "32Gi"
                requests:
                  cpu: "8"
                  memory: "32Gi"
              volumeMounts:
                - name: scripts
                  mountPath: /home/ray/scripts
                - name: cluster-storage
                  mountPath: /mnt/cluster_storage
          volumes:
            - name: scripts
              configMap:
                name: entity-recognition-scripts
                items:
                  - key: entity_recognition.py
                    path: entity_recognition.py
            - name: cluster-storage
              persistentVolumeClaim:
                claimName: cluster-storage

    workerGroupSpecs:
      - groupName: workers
        replicas: 2
        minReplicas: 2
        maxReplicas: 4
        rayStartParams:
          num-gpus: "8"
          num-cpus: "64"
        template:
          spec:
            # No init containers needed â€” workers see the same shared storage
            containers:
              - name: ray-worker
                image: rayproject/ray:2.53.0-gpu
                resources:
                  limits:
                    cpu: "64"
                    memory: "64Gi"
                    nvidia.com/gpu: "8"
                  requests:
                    cpu: "64"
                    memory: "64Gi"
                    nvidia.com/gpu: "8"
                volumeMounts:
                  - name: cluster-storage
                    mountPath: /mnt/cluster_storage
            volumes:
              - name: cluster-storage
                persistentVolumeClaim:
                  claimName: cluster-storage
